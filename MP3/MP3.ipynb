{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECSE-551 Mini Project 3\n",
    "Authors:\n",
    "* Ashley Meagher (260822930)\n",
    "* Charles Sirois (261158513)  \n",
    "* Emma ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install neptune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import neptune\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "from pathlib import Path\n",
    "folder_path = Path('drive/MyDrive/Colab Notebooks/ECSE 551_MP3')\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import data_table\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.insert(0, folder_path)\n",
    "\n",
    "# My functions\n",
    "from data_loader import create_dataloaders\n",
    "from model import get_model, get_optimizer, get_loss_fn, log_model_info\n",
    "from training import train_model, predict\n",
    "import utils\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "To train models for a given set of hyperparameters. Log experiments results to Neptune.ai. See [here]() for the project's dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def train_all_models(hyperparameters_options):\n",
    "    '''\n",
    "    To train a model for all the set of parameters specified\n",
    "    '''\n",
    "    print(f'Training all models')\n",
    "\n",
    "    # Create list with all options\n",
    "    keys, values = zip(*hyperparameters_options.items())\n",
    "    hp_options_list = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    for idx, each_hp_set in enumerate(hp_options_list):\n",
    "        print(f'\\n\\n-------------------- Model {idx+1}/{len(hp_options_list)} --------------------')\n",
    "        print('Hyperparameters:')\n",
    "        print(each_hp_set)\n",
    "\n",
    "        start_model_training(each_hp_set)\n",
    "\n",
    "\n",
    "def start_model_training(hyperparameters: dict):\n",
    "    \"\"\"To train a model with the given hyperparameters. Required fields:\n",
    "        - seed\n",
    "\n",
    "        - img_size\n",
    "        - train_batch_size\n",
    "        - test_batch_size\n",
    "\n",
    "        - model_name\n",
    "        - act_fn\n",
    "        - dropout_prob\n",
    "\n",
    "        - optimizer\n",
    "        - n_epoch\n",
    "        - lr\n",
    "        - momentum\n",
    "\n",
    "        - loss_fn\n",
    "\n",
    "    Args:\n",
    "        hyperparameters (dict): _description_\n",
    "    \"\"\"\n",
    "    print(f\"------- Model -------\")\n",
    "    # --- Hyperparameters ---\n",
    "    train_batch_size = hyperparameters['train_batch_size']\n",
    "    test_batch_size = hyperparameters['test_batch_size']\n",
    "    img_size = hyperparameters['img_size']\n",
    "\n",
    "    # Model\n",
    "    model_name = hyperparameters['model_name']\n",
    "\n",
    "    act_fn = hyperparameters['act_fn']\n",
    "    dropout_prob = hyperparameters['dropout_prob']\n",
    "\n",
    "    # Optim\n",
    "    n_epochs = hyperparameters['n_epoch']\n",
    "    optimizer_type = hyperparameters['optimizer']\n",
    "    lr = hyperparameters['lr']\n",
    "    momentum = hyperparameters['momentum']\n",
    "\n",
    "    # Loss\n",
    "    loss_fn = hyperparameters['loss_fn']\n",
    "\n",
    "    # --- Setup Run ---\n",
    "    run_name = utils.generate_run_name(model_name)\n",
    "    print(f\"Model: {model_name}\\t Neptune run: {run_name}\")\n",
    "    run = neptune.init_run(\n",
    "        project=\"MyResearch/ECSE551-MP3\",\n",
    "        api_token=NEPTUNE_API,\n",
    "        custom_run_id=run_name,\n",
    "        source_files=[\"MP3/*.py\"],\n",
    "    )\n",
    "\n",
    "    # Log hyperparameters\n",
    "    run[\"parameters\"] = hyperparameters\n",
    "\n",
    "    # ---- Load Data ---\n",
    "    train_dl, val_dl, _, full_train_dl = create_dataloaders(\n",
    "        img_size, train_batch_size, test_batch_size, print_ds_infos=False, neptune_run=run\n",
    "    )\n",
    "\n",
    "    # --- Train Model ---\n",
    "    model = get_model(\n",
    "        model_type=model_name, act_fn=act_fn, dropout_prob=dropout_prob, img_size=img_size\n",
    "    )\n",
    "    log_model_info(model, img_size, run)\n",
    "\n",
    "    optimizer = get_optimizer(model, type=optimizer_type, lr=lr, momentum=momentum)\n",
    "\n",
    "    loss_fn = get_loss_fn(loss_fn)\n",
    "\n",
    "    results = train_model(model, train_dl, val_dl, optimizer, loss_fn, n_epochs, run)\n",
    "\n",
    "    run.stop()\n",
    "\n",
    "    # utils.plot_training_loss(results)\n",
    "    # utils.plot_training_acc(results)\n",
    "\n",
    "\n",
    "def load_run(\n",
    "    run_id: str, retrain: bool\n",
    ") -> Tuple[nn.Module, List[torch.utils.data.DataLoader]]:  # (model, [full_train_dl , test_dl])\n",
    "    \"\"\"Load all the info from a previous run. If the model is not to be retrained, load the models'\n",
    "    weights and optimizer state (TODO)\n",
    "\n",
    "    Args:\n",
    "        run_id (str): _description_\n",
    "        retrain (bool): If the model is to be retrained from 0 on the full dataset (train+val)\n",
    "\n",
    "    Returns:\n",
    "        Tuple[nn.Module, List[torch.utils.data.DataLoader]]: _description_\n",
    "    \"\"\"\n",
    "    # --- Load data ---\n",
    "    print(f\"Loading run from Neptune: {run_id}\")\n",
    "\n",
    "    run = neptune.init_run(\n",
    "        project=\"MyResearch/ECSE551-MP3\", with_id=run_id, api_token=NEPTUNE_API, mode=\"read-only\"\n",
    "    )\n",
    "\n",
    "    model_id = run[\"sys/custom_run_id\"].fetch()\n",
    "    model_params = run[\"parameters\"].fetch()\n",
    "    model_type = model_id.split('_')[0]\n",
    "\n",
    "    # --- Hyperparameters ---\n",
    "    # Datasets\n",
    "    train_batch_size = model_params[\"train_batch_size\"]\n",
    "    test_batch_size = model_params[\"test_batch_size\"]\n",
    "    img_size = model_params[\"img_size\"]\n",
    "\n",
    "    # Model\n",
    "    act_fn = model_params[\"act_fn\"]\n",
    "    dropout_prob = model_params[\"dropout_prob\"]\n",
    "\n",
    "    # Optim\n",
    "    n_epochs = model_params[\"n_epoch\"]\n",
    "    optimizer_type = model_params[\"optimizer\"]\n",
    "    lr = model_params[\"lr\"]\n",
    "    momentum = model_params[\"momentum\"]\n",
    "\n",
    "    # Loss\n",
    "    loss_fn = model_params[\"loss_fn\"]\n",
    "\n",
    "    # --- Model ---\n",
    "    model = get_model(\n",
    "        model_type=model_type, act_fn=act_fn, dropout_prob=dropout_prob, img_size=img_size\n",
    "    )\n",
    "    if not retrain:\n",
    "        weights_path = Path(\"MP3/models\") / model_id / \"model.pth\"\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "    # --- Optim ---\n",
    "    optimizer = get_optimizer(model, type=optimizer_type, lr=lr, momentum=momentum)\n",
    "    if not retrain:\n",
    "        # Load the optimizer state\n",
    "        optim_path = Path(\"MP3/models\") / model_id / \"optimizer.pth\"\n",
    "        optimizer.load_state_dict(torch.load(optim_path))\n",
    "\n",
    "    # --- Loss ---\n",
    "    loss_fn = get_loss_fn(loss_fn)\n",
    "\n",
    "    # --- Datasets ---\n",
    "    train_dl, val_dl, test_dl, full_train_dl = create_dataloaders(\n",
    "        img_size, train_batch_size, test_batch_size, print_ds_infos=False, neptune_run=None\n",
    "    )\n",
    "\n",
    "    run.stop()\n",
    "    print('Done loading')\n",
    "\n",
    "    return (\n",
    "        model_id,\n",
    "        model,\n",
    "        [train_dl, full_train_dl, val_dl, test_dl],\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        n_epochs,\n",
    "        model_params,\n",
    "    )\n",
    "\n",
    "\n",
    "def test_model(run_id, n_test_epochs, retrain=True):\n",
    "    (\n",
    "        model_id,\n",
    "        model,\n",
    "        (train_dl, full_train_dl, val_dl, test_dl),\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        n_train_epochs,\n",
    "        hyperparams,\n",
    "    ) = load_run(run_id, retrain=retrain)\n",
    "\n",
    "    if retrain:\n",
    "        model_id += f'_Test_{n_test_epochs}'\n",
    "        print(f'Starting new training: {model_id}')\n",
    "        train_run = neptune.init_run(\n",
    "            project=\"MyResearch/ECSE551-MP3\",\n",
    "            api_token=NEPTUNE_API,\n",
    "            custom_run_id=model_id,\n",
    "            source_files=[\"MP3/*.py\"],\n",
    "        )\n",
    "        hyperparams['n_epoch'] = n_test_epochs\n",
    "        train_run[\"parameters\"] = hyperparams\n",
    "        train_model(model, full_train_dl, val_dl, optimizer, loss_fn, n_test_epochs, train_run)\n",
    "        train_run.stop()\n",
    "\n",
    "    y_test = predict(model, test_dl)\n",
    "\n",
    "    pred_df = pd.DataFrame(y_test, columns=['class'])\n",
    "    pred_df.index.name = 'id'\n",
    "    pred_save_path = Path('MP3/predictions') / f'{model_id}.csv'\n",
    "    pred_df.to_csv(pred_save_path)\n",
    "    print(f'Predictions saved to {pred_save_path}')\n",
    "\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of experiments\n",
    "LR_EXP_HP_OPTIONS = {\n",
    "    \"seed\": [SEED],\n",
    "    # Dataset\n",
    "    \"img_size\": [32],\n",
    "    \"train_batch_size\": [64],\n",
    "    \"test_batch_size\": [64],\n",
    "    # Model\n",
    "    \"model_name\": [\"LeNet5\"],  # \"MyNet\", \"LeNet5\", \"VGG11\", \"VGG13\", \"VGG16\"\n",
    "    \"act_fn\": [\"ReLu\"],\n",
    "    \"dropout_prob\": [0.15],\n",
    "    # Optim\n",
    "    \"optimizer\": [\"Adam\"],\n",
    "    \"n_epoch\": [100],\n",
    "    \"lr\": [0.01, 1e-3, 1e-4, 1e-5],\n",
    "    \"momentum\": [0.5],\n",
    "    # Loss\n",
    "    \"loss_fn\": [\"cross_entropy\"],  # 'cross_entropy', 'nll'\n",
    "}\n",
    "\n",
    "BATCH_SIZE_EXP_HP_OPTIONS = {\n",
    "    \"seed\": [SEED],\n",
    "    # Dataset\n",
    "    \"img_size\": [32],\n",
    "    \"train_batch_size\": [32, 64, 128, 256, 512],\n",
    "    \"test_batch_size\": [64],\n",
    "    # Model\n",
    "    \"model_name\": [\"LeNet5\"],  # \"MyNet\", \"LeNet5\", \"VGG11\", \"VGG13\", \"VGG16\"\n",
    "    \"act_fn\": [\"ReLu\"],\n",
    "    \"dropout_prob\": [0.15],\n",
    "    # Optim\n",
    "    \"optimizer\": [\"Adam\"],\n",
    "    \"n_epoch\": [10],\n",
    "    \"lr\": [1e-3],\n",
    "    \"momentum\": [0.5],\n",
    "    # Loss\n",
    "    \"loss_fn\": [\"cross_entropy\"],  # 'cross_entropy', 'nll'\n",
    "}\n",
    "\n",
    "ACT_FN_EXP_HP_OPTIONS = {\n",
    "    \"seed\": [SEED],\n",
    "    # Dataset\n",
    "    \"img_size\": [32],\n",
    "    \"train_batch_size\": [128],\n",
    "    \"test_batch_size\": [128],\n",
    "    # Model\n",
    "    \"model_name\": [\"LeNet5\"],  # \"MyNet\", \"LeNet5\", \"VGG11\", \"VGG13\", \"VGG16\"\n",
    "    \"act_fn\": [\"ReLu\", \"Tanh\", \"LeakyReLU\", 'Sigmoid'],\n",
    "    \"dropout_prob\": [0.15],\n",
    "    # Optim\n",
    "    \"optimizer\": [\"Adam\"],\n",
    "    \"n_epoch\": [10],\n",
    "    \"lr\": [1e-3],\n",
    "    \"momentum\": [0.5],\n",
    "    # Loss\n",
    "    \"loss_fn\": [\"cross_entropy\"],  # 'cross_entropy', 'nll'\n",
    "}\n",
    "\n",
    "LOSS_EXP_HP_OPTIONS = {\n",
    "    \"seed\": [SEED],\n",
    "    # Dataset\n",
    "    \"img_size\": [32],\n",
    "    \"train_batch_size\": [128],\n",
    "    \"test_batch_size\": [128],\n",
    "    # Model\n",
    "    \"model_name\": [\"LeNet5\"],  # \"MyNet\", \"LeNet5\", \"VGG11\", \"VGG13\", \"VGG16\"\n",
    "    \"act_fn\": [\"ReLu\"],\n",
    "    \"dropout_prob\": [0.15],\n",
    "    # Optim\n",
    "    \"optimizer\": [\"Adam\"],\n",
    "    \"n_epoch\": [10],\n",
    "    \"lr\": [1e-3],\n",
    "    \"momentum\": [0.5],\n",
    "    # Loss\n",
    "    \"loss_fn\": [\"cross_entropy\", 'nll'],  # 'cross_entropy', 'nll'\n",
    "}\n",
    "\n",
    "BEST_MODEL_EXP = {\n",
    "    \"seed\": [SEED],\n",
    "    # Dataset\n",
    "    \"img_size\": [32, 64],\n",
    "    \"train_batch_size\": [256],\n",
    "    \"test_batch_size\": [256],\n",
    "    # Model\n",
    "    \"model_name\": [\"VGG13\", \"VGG16\"],  # \"MyNet\", \"LeNet5\", \"VGG11\", \"VGG13\", \"VGG16\"\n",
    "    \"act_fn\": [\"LeakyReLU\"],\n",
    "    \"dropout_prob\": [0, 0.1, 0.15, 0.2],\n",
    "    # Optim\n",
    "    \"optimizer\": [\"Adam\"],\n",
    "    \"n_epoch\": [25],\n",
    "    \"lr\": [1e-3],\n",
    "    \"momentum\": [0],\n",
    "    # Loss\n",
    "    \"loss_fn\": [\"cross_entropy\"],  # 'cross_entropy', 'nll'\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for a given experiment\n",
    "hyperparameters_options = BEST_MODEL_EXP  # set this to the desired experiment\n",
    "train_all_models(hyperparameters_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Will load the model of a given neptune run id and retrain it on the train+val datasets for the given number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"MP3-125\"\n",
    "n_epochs = 25\n",
    "test_model(run_id, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "To plot the results of the various experiments. Loads the data from the neptune board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_results\n",
    "\n",
    "plot_results.lenet5_lr_plots()\n",
    "\n",
    "plot_results.lenet5_batch_size_plots()\n",
    "\n",
    "plot_results.lenet5_act_fn_plots()\n",
    "\n",
    "plot_results.lenet5_loss_plots()\n",
    "\n",
    "plot_results.plot_best_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
